{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjzK2r_unKzN"
   },
   "source": [
    "\n",
    "# **TESTES DE HIP√ìTESES - PARTE 1(Definindo Teste de Hip√≥teses)**\n",
    "\n",
    "O teste de hip√≥tese √© um tipo de an√°lise estat√≠stica em que voc√™ testa suas suposi√ß√µes sobre um par√¢metro populacional. √â usado para estimar a rela√ß√£o entre 2 vari√°veis estat√≠sticas.\n",
    "\n",
    "Vamos discutir alguns exemplos de hip√≥teses estat√≠sticas da vida real:\n",
    "\n",
    "‚Ä¢\tUm professor sup√µe que 10% dos alunos de sua faculdade v√™m de fam√≠lias de classe alta.\n",
    "‚Ä¢\tUm m√©dico acredita o tratamento contra a obesidade √© 40% eficaz para pacientes diab√©ticos.\n",
    "\n",
    "Agora que voc√™ conhece o teste de hip√≥tese, veja os dois tipos de teste de hip√≥tese em estat√≠stica.\n",
    "\n",
    "A hip√≥tese nula √© a suposi√ß√£o de que o evento n√£o ocorrer√°. Uma hip√≥tese nula n√£o tem influ√™ncia sobre o resultado do estudo, a menos que seja rejeitada.\n",
    "\n",
    "**H0 √© o s√≠mbolo para isso, e √© pronunciado H-nula.**\n",
    "\n",
    "A hip√≥tese alternativa √© o oposto l√≥gico da hip√≥tese nula. A aceita√ß√£o da hip√≥tese alternativa segue a rejei√ß√£o da hip√≥tese nula. H1 √© o s√≠mbolo para isso.\n",
    "\n",
    "\n",
    "\n",
    "Vamos entender isso com um exemplo.\n",
    "\n",
    "Um fabricante de desinfetante afirma que seu produto mata 45% dos germes em m√©dia.\n",
    "Para testar a afirma√ß√£o dessa empresa, crie uma hip√≥tese nula e alternativa.\n",
    "\n",
    "H0 (Hip√≥tese Nula): M√©dia = 95%.\n",
    "Hip√≥tese alternativa (H1): A m√©dia √© inferior a 95%. **negrito**\n",
    "\n",
    "Outro exemplo direto para entender esse conceito √© determinar se uma moeda √© cara ou coroa. A hip√≥tese nula afirma que a probabilidade de dar cara √© igual √† probabilidade de dar coroa. Em contraste, a teoria alternativa afirma que a probabilidade de uma exibi√ß√£o de caras e coroas seria muito diferente.\n",
    "Dependendo da distribui√ß√£o da popula√ß√£o, voc√™ pode classificar a hip√≥tese estat√≠stica em dois tipos.\n",
    "Hip√≥tese Simples: Uma hip√≥tese simples especifica um valor exato para o par√¢metro.\n",
    "Hip√≥tese composta: Uma hip√≥tese composta especifica um intervalo de valores.\n",
    "\n",
    "***N√≠vel de signific√¢ncia***\n",
    "\n",
    "O valor alfa √© um crit√©rio para determinar se uma estat√≠stica de teste √© estatisticamente significativa. Em um teste estat√≠stico, Alfa representa uma probabilidade aceit√°vel de um erro Tipo I. Como alfa √© uma probabilidade, pode estar entre 0 e 1. Na pr√°tica, os valores de alfa mais comumente usados s√£o 0,01, 0,05 e 0,1, que representam 1%, 5% e 10% de chance de um erro Tipo I , respectivamente (ou seja, rejeitar a hip√≥tese nula quando ela √© de fato correta).\n",
    "\n",
    "***Valor P***\n",
    "\n",
    "Um valor-p √© uma m√©trica que expressa a probabilidade de uma diferen√ßa observada ter ocorrido por acaso. √Ä medida que o valor-p diminui, a signific√¢ncia estat√≠stica da diferen√ßa observada aumenta. Se o valor-p for muito baixo, voc√™ rejeita a hip√≥tese nula.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iPUNYr6q2Hy"
   },
   "source": [
    "# **TESTES DE HIP√ìTESES - PARTE 2(Etapas de Constru√ß√£o de um Teste de Hip√≥tese)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhpBzWPcrkQK"
   },
   "source": [
    "A empresa Suco Bom produz sucos de frutas em embalagens de 500 ml. Seu processo de produ√ß√£o √© quase todo automatizado e as embalagens de sucos s√£o preenchidas por uma m√°quina que √†s vezes apresenta um certo desajuste, levando a erros no preenchimento das embalagens para mais ou menos conte√∫do. Quando o volume m√©dio cai abaixo de 500 ml, a empresa se preocupa em perder vendas e ter problemas com os org√£os fiscalizadores. Quando o volume passa de 500 ml, a empresa come√ßa a se preocupar com preju√≠zos no processo de produ√ß√£o.\n",
    "\n",
    "O setor de controle de qualidade da empresa Suco Bom extrai, periodicamente, amostras de 50 embalagens para monitorar o processo de produ√ß√£o. Para cada amostra, √© realizado um teste de hip√≥teses para avaliar se o maquin√°rio se desajustou. A equipe de controle de qualidade assume um n√≠vel de signific√¢ncia de 5%.\n",
    "\n",
    "Suponha agora que uma amostra de 50 embalagens foi selecionada e que a m√©dia amostral observada foi de 503,24 ml e desvio padrao 4,48. Esse valor de m√©dia amostral √© suficientemente maior que 500 ml para nos fazer rejeitar a hip√≥tese de que a m√©dia do processo √© de 500 ml ao n√≠vel de signific√¢ncia de 5%?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QaHVGcy9rpcP"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from numpy import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0EGUdkj9rvzv"
   },
   "outputs": [],
   "source": [
    "# Hipotese de ser igual, significa um bicaudal com h0 da medias serem iguais\n",
    "# ùêª0:ùúá=500 \n",
    "# ùêª1:ùúá‚â†500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FimRfV3mryVc"
   },
   "outputs": [],
   "source": [
    "u = 500\n",
    "n = 50\n",
    "sig = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gP9Xauqsr1BK",
    "outputId": "59e35c31-f65c-4357-cb96-6ad388098141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.9599639845400545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.113897256795581"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_sig_sob2 = norm.ppf(sig/2)\n",
    "print(z_sig_sob2)\n",
    "x = 503.24\n",
    "s = 4.48\n",
    "z = (x-u)/(s/sqrt(n))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqpPx5-Cr7mm",
    "outputId": "d0c818e5-d341-4f30-880c-3b369e4449d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999998422104751\n",
      "3.155790497810784e-07\n",
      "Rejeita h0\n"
     ]
    }
   ],
   "source": [
    "area = norm.cdf(z)\n",
    "print(area)\n",
    "pvalor = 2*(1-area)\n",
    "print(pvalor)\n",
    "if (pvalor <= sig):\n",
    "    print('Rejeita h0')\n",
    "else:\n",
    "    print('Aceita h0')\n",
    "\n",
    "#Rejeitar  ùêª0  se o valor  ùëù‚â§ùõº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRhf9iR1sC0v"
   },
   "source": [
    "# **TESTES DE HIP√ìTESES - PARTE 3(Definindo M√©todo de Neyman-Pearson)**\n",
    "\n",
    "\n",
    "O paradigma NP visa corrigir esse problema abordando diretamente os erros de classifica√ß√£o assim√©tricos. O objetivo √© maximizar a taxa de verdadeiros positivos (TP) enquanto se mant√©m a taxa de falsos positivos (FP) dentro de um limite aceit√°vel. Isso √© conseguido atrav√©s da maximiza√ß√£o da Raz√£o de Verdadeiros Positivos (TPR) e da minimiza√ß√£o da Raz√£o de Falsos Positivos (FPR) - duas m√©tricas de avalia√ß√£o de desempenho amplamente utilizadas no mundo da classifica√ß√£o bin√°ria. O paradigma NP √© amplamente usado em aplica√ß√µes onde os erros de classifica√ß√£o assim√©tricos s√£o preocupa√ß√µes centrais, como detec√ß√£o de fraudes, diagn√≥stico m√©dico e detec√ß√£o de uso indevido.\n",
    "\n",
    "O uso do paradigma de classifica√ß√£o NP tem se mostrado bastante √∫til para melhorar a precis√£o de classifica√ß√£o de dados. Por exemplo, ao processar dados de imagem, √© poss√≠vel detectar erros de classifica√ß√£o mais graves e minimizar os erros menos graves. Isso √© particularmente √∫til para aplica√ß√µes m√©dicas, onde √© necess√°rio um alto n√≠vel de precis√£o para evitar erros potencialmente fatais. Al√©m disso, o uso do paradigma de classifica√ß√£o NP torna poss√≠vel a classifica√ß√£o de dados heterog√™neos e em grande escala, o que √© essencial para aplica√ß√µes m√≥veis e na web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0skbbituV2C"
   },
   "source": [
    "# **TESTES DE HIP√ìTESES - PARTE 4(Neyman-Pearson na Pr√°tica)**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nw71yzAEvnqM",
    "outputId": "1909cbc6-5e4b-4d2b-b7a4-bf81c9d35736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting nproc\n",
      "  Downloading nproc-1.5.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nproc) (1.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from nproc) (1.21.6)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from nproc) (1.7.3)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=c092b0da1f2b190d457f4f1aaad56cd41af303980136fb4a76214f3be02c9378\n",
      "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn, nproc\n",
      "Successfully installed nproc-1.5.2 sklearn-0.0.post1\n"
     ]
    }
   ],
   "source": [
    "pip install nproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eSoxifJTw5Dv"
   },
   "outputs": [],
   "source": [
    "from nproc import npc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xOaYinC8xFXV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nproc import npc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7z-EjMqAxwER"
   },
   "outputs": [],
   "source": [
    "test = npc()\n",
    "\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DdSGikS_x0Vp"
   },
   "outputs": [],
   "source": [
    "# Crie um conjunto de dados (x,y) com 2 recursos, r√≥tulo bin√°rio e tamanho de amostra 10000.\n",
    "n = 10000\n",
    "x = np.random.normal(0, 1, (n,2))\n",
    "c = 1+3*x[:,0]\n",
    "y = np.random.binomial(1, 1/(1+np.exp(-c)), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YrTS7DBex4cg"
   },
   "outputs": [],
   "source": [
    "# Chame a fun√ß√£o npc para construir classificadores Neyman-Pearson.\n",
    "# O limite superior padr√£o da taxa de erro tipo I √© alfa=0,05.\n",
    "fit = test.npc(x, y, 'logistic', n_cores=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "B1RqtSbQx_G6"
   },
   "outputs": [],
   "source": [
    "# Avalie a predi√ß√£o do ajuste do classificador NP em um conjunto de teste (xtest, ytest).\n",
    "x_test = np.random.normal(0, 1, (n,2))\n",
    "c_test = 1+3*x_test[:,0]\n",
    "y_test = np.random.binomial(1, 1/(1+np.exp(-c_test)), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hg3HCQ1EyDe6",
    "outputId": "ebb1b586-2f6c-468f-de0e-7712488c707d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.7268\n",
      "Accuracy on test set: 0.7243\n"
     ]
    }
   ],
   "source": [
    "#Calcule a precis√£o geral do classificador, bem como a realizada\n",
    "# taxa de erro tipo I em dados de teste.\n",
    "# Estritamente falando, para demonstrar a efic√°cia do classificador de ajuste\n",
    "# sob o paradigma NP, devemos repetir este experimento muitas vezes, e\n",
    "# mostra que em 1 - delta dessas repeti√ß√µes, a taxa de erro tipo I √© menor que alfa.\n",
    "\n",
    "fitted_score = test.predict(fit,x)\n",
    "print(\"Accuracy on training set:\", accuracy_score(fitted_score[0], y))\n",
    "pred_score = test.predict(fit,x_test)\n",
    "print(\"Accuracy on test set:\", accuracy_score(pred_score[0], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tnpq1oYDyIia",
    "outputId": "ebda985e-9d30-4c10-c508-3ae260b0031f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[3816  125]\n",
      " [2632 3427]]\n",
      "Type I error rate: 0.03172\n",
      "Type II error rate: 0.43440\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, pred_score[0])\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"Type I error rate: {:.5f}\".format(fp/(fp+tn)))\n",
    "print(\"Type II error rate: {:.5f}\".format(fn/(fn+tp)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
